创建kernel的convolution的构造函数中grid_tiled_shape是从device的initialization里出来的，ref_src就是源数据的ref，它的大小应该就是整个输入的大小，它的layout将传给对应iterator的params作为初始化

kernel级别convolution的Mma的Shape是thread block的大小，是device级别的default里就有给定的

kernel级别的convolution中conv_c_iterations是$\ceil(IC/Mma::Shape::kK)$

can_implement是通过检查对齐进行判断的，指标是元素数，iterator的access type中的kElements和ref自己的layout的stride

提供grid_tiled_shape就是thread swizzle的get_tiled_shape方法

在kernel级别的convolution中，真正跑一个convolution的过程：

- threadblock swizzle提供一个threadblock_tile_offset，方法是get_tile_offset。根据已有的两种实现
CxRSKx中：
  tile_M = blockDim.x
  tile_N = blockDim.y
  tile_K = blockDim.z
  gridDim.x = P*Q
  gridDim.y = ceil(N/tile_N)
  gridDim.z = ceil(K/tile_M)
  offset_P = blockIdx.x / Q
  offset_Q = blockIdx.x - offset_P * Q
  offset_K = blockIdx.z * tile_M
  offset_N = blockIdx.y * tile_N
NCxHWx:
  tile_M = blockDim.x
  tile_N = blockDim.y
  tile_K = blockDim.z
  gridDim.x = ceil(N * P * Q / tile_N)
  gridDim.y = ceil(K/tile_M)
  gridDim.z = 1
  offset_m = blockIdx.y * tile_M
  offset_n = blockIdx.x * tile_N
  offset_k = 1
  注意它返回的offset是gemm coord
  从kernel级别的convolution来看应该是没用到

- 计算每个threadblock的卷积各个维度的offset，在这里处理了padding的问题，kh, kw的含义也是filter的offset(因为padding的存在导致的)

- kernel级别的convolution在填模板参数的时候，default_convolution决定了五种参数组合，包括Nx，Cx的dp4a，Cx的tensor op，还有两个混合的tensor op。default_convolution选block Mma的时候用的是default mma，default mma也有五种选择，dp4a的有CCC, NCN4, NCN32, tensor op的有CCC, NCX。default_mma确定block mma，it src和it filter，用的是default mma core。default mma core分两种: dp4a和tensor op，dp4a分别给CCX和NCX，tensor op只给NC。

- default mma dp4a的CCX选择：
  - 首先对于shared mem, filter矩阵用column major interleaved 4, src矩阵用row major interleaved 4
  - src thread map是pitch linear strip mined，这个thread map在给定区域里计算每个thread的offset，iterations和移动delta，单位是4个4个元素数的
  - it src用了src thread map，本身是个regular tile iterator，管理的区域大小为blockDim.z(K), blockDim.y(N)，用的layout是shared mem的src的layout, advance rank是0。由于这也不是tensor op，所以猜测使用的是regular tile iterator pitch linear里的，这里有五个iterator，只有第一个是本质的，其它的都借助第一个实现(PitchLinear)。第一个iterator在初始化的时候就记录几个值，increment_strided_是每个thread每次沿strided方向动一个iteration时候访存指针要移动的bytes，increment_advance_是移动到下一个tile的对应位置访存指针要动的byte，一般根据方向，advance rank = 0的时候是一横行（contiguous方向）,advance rank = 1的时候是整个块的bytes数(strided方向)
  - Policy只有一个负责给出lane layout的接口
  - MmaWarpSimt是MmaSimt，结果是RowMajor的。这个warp级别的Mma进一步确定一个thread级别的Mma，thread级别的Mma则是从arch里选Mma。我们这里的dp4a应该是sm61开始有